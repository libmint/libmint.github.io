
---

## ğŸ“˜ README.md

```markdown
# GUI Perception and Dataset Builder (UI-TARS Style)

This project enables automatic analysis, transformation, and enhancement of GUI screenshots into structured, multi-task training dataâ€”aligned with the UI-TARS paper format. It supports:

- âœ¨ Multi-task GUI perception (captioning, element detection, QA, etc.)
- ğŸ“‚ Bulk conversion from existing datasets
- ğŸ¤– Filling incomplete data via GPT-4o vision models
- ğŸ“¦ Modular architecture for maintainability and scalability

---

## ğŸ“ Project Structure

```

gui\_project/
â”œâ”€â”€ main.py                         # Entry point for all operations
â”œâ”€â”€ model\_utils.py                  # GPT-4o API + image encoding logic
â”œâ”€â”€ aw\_data\_converter/
â”‚   â”œâ”€â”€ **init**.py
â”‚   â””â”€â”€ data\_utils.py              # Old â†’ new format converter & answer filler
â”œâ”€â”€ gui\_tasks/
â”‚   â”œâ”€â”€ base\_task.py
â”‚   â”œâ”€â”€ element\_description\_task.py
â”‚   â”œâ”€â”€ dense\_captioning\_task.py
â”‚   â”œâ”€â”€ qa\_task.py
â”‚   â”œâ”€â”€ set\_of\_mark\_task.py
â”‚   â””â”€â”€ state\_transition\_captioning\_task.py

````

---

## ğŸš€ Quick Start

### ğŸ”¹ 1. Convert Legacy Format

```bash
python main.py convert \
  --input old_format.json \
  --output converted_data.json
````

### ğŸ”¹ 2. Fill Unknown Answers using GPT-4o

```bash
python main.py fill \
  --input converted_data.json \
  --image_dir screenshots/ \
  --output completed_data.json
```

### ğŸ”¹ 3. Run Perception Tasks (Single or Batch)

```bash
python main.py run \
  --image_dir screenshots/ \
  --all \
  --output gui_result.json
```

Or run only one task:

```bash
python main.py run \
  --image screenshots/home.png \
  --task qa \
  --question "What is the purpose of this screen?" \
  --output result_qa.json
```

---

## ğŸ§  Supported Tasks

* `element_description` â€“ bounding boxes, types, visuals, functions
* `dense_captioning` â€“ natural language overview
* `qa` â€“ screen-level question answering
* `set_of_mark` â€“ identify highlighted/selected elements
* `state_transition_captioning` â€“ explain UI state changes between two screenshots

---

## ğŸ” .env Configuration

Create a `.env` file in the root with the following:

```env
API_KEY=your_openai_api_key
API_ENDPOINT=http://your.gpt4o.server/chat/completions
MODEL_NAME=gpt-4o
```

---

## ğŸ› ï¸ Requirements

```bash
pip install python-dotenv requests
```

---

## ğŸ§© Extending the Project

* Add new data converters to `aw_data_converter/`
* Add new GUI tasks by extending `BaseGUITask` in `gui_tasks/`
* Easily adapt to other LLM APIs by modifying `model_utils.py`

---

## ğŸ“„ License

MIT License

---

## âœï¸ Author

Created by \[Your Name]. Contributions welcome.

```

---

