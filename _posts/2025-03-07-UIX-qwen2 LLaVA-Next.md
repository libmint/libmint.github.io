ì£¼ì–´ì§„ LLaVAì˜ ì˜ˆì œ ì½”ë“œ(`model_vqa.py`)ì™€ ìœ ì‚¬í•œ í˜•íƒœë¡œ, UIX-qwen2 ëª¨ë¸ì„ ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ë¡œë“œí•˜ê³  ì´ë¯¸ì§€ì™€ ì§ˆë¬¸(prompt)ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê²°ê³¼ë¥¼ ì¶”ë¡ í•˜ëŠ” ì˜ˆì œ ì½”ë“œë¥¼ ì•„ë˜ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¤ìŒì˜ ì½”ë“œëŠ” `UIX-qwen2` ëª¨ë¸ì˜ ê³µì‹ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ê°€ì •í•˜ì—¬ ì‘ì„±í•œ ì˜ˆì œ í…œí”Œë¦¿ í˜•íƒœì…ë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ í™˜ê²½ì—ì„œ ì¼ë¶€ í´ë˜ìŠ¤ë‚˜ í•¨ìˆ˜ ì´ë¦„ì´ ë‹¤ë¥´ë‹¤ë©´ ì•½ê°„ì˜ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## â­ï¸ UIX-qwen2 ëª¨ë¸ì„ í™œìš©í•œ Visual Question Answering ì¶”ë¡  ì½”ë“œ (`model_vqa_qwen2.py`)

### ì¤€ë¹„ì‚¬í•­

```bash
pip install torch transformers Pillow
```

---

## ì½”ë“œ ì˜ˆì œ (`model_vqa_qwen2.py`)

```python
import torch
from PIL import Image
from transformers import AutoModelForCausalLM, AutoProcessor

def load_model_qwen2(model_path, device='cuda'):
    """
    UIX-qwen2 ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    """
    processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True).to(device)
    model.eval()

    return processor, model

@torch.no_grad()
def infer_qwen2(processor, model, image, prompt, device='cuda'):
    """
    ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì•„ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    inputs = processor(prompt, image, return_tensors='pt').to(device)

    # Generate ë‹µë³€ (max_length, temperature ë“± íŒŒë¼ë¯¸í„° ì„¤ì • ê°€ëŠ¥)
    output_ids = model.generate(**inputs, max_length=512, do_sample=False)
    response = processor.decode(output_ids[0], skip_special_tokens=True)

    return response

def main():
    model_path = 'UIX-Engineering/UIX-qwen2' # ëª¨ë¸ ê²½ë¡œ (ë¡œì»¬ ë˜ëŠ” huggingface repo id)
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    image_path = "your_image.jpg" # ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥
    prompt = "ì´ ì´ë¯¸ì§€ì—ì„œ ë¬´ì—‡ì´ ë³´ì´ë‚˜ìš”?"

    # ëª¨ë¸ ë¡œë“œ
    processor, model = load_model_qwen2(model_path, device=device)

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path).convert('RGB')

    # ì¶”ë¡  ìˆ˜í–‰
    answer = infer_qwen2(processor, model, image, prompt, device)
    print("ë‹µë³€:", answer)

if __name__ == '__main__':
    main()
```

---

## ğŸ“Œ ì½”ë“œ ì„¤ëª… 

- **load_model_qwen2**:  
  ëª¨ë¸ê³¼ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ processor(tokenizer & image processor)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.  
  `trust_remote_code=True`ëŠ” UIX-qwen2 ê°™ì€ ì»¤ìŠ¤í…€ ëª¨ë¸ ì½”ë“œì— í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **infer_qwen2**:  
  ì´ë¯¸ì§€ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.  
  ë‚´ë¶€ì ìœ¼ë¡œ processorê°€ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ë¥¼ í•´ë‹¹ ëª¨ë¸ì˜ ì…ë ¥ í˜•ì‹ì— ë§ì¶”ì–´ ì¸ì½”ë”©í•©ë‹ˆë‹¤.

- **main í•¨ìˆ˜**:  
  ìœ„ì˜ ë‘ í•¨ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ ëª¨ë¸ ë¡œë“œ ë° ì´ë¯¸ì§€ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µì„ ì™„ì„±í•©ë‹ˆë‹¤.

---

## ğŸ”– ì£¼ì˜ì‚¬í•­

- ìœ„ ì½”ë“œëŠ” UIX-qwen2ì˜ ê³µì‹ ì˜ˆì‹œ ì½”ë“œë¥¼ ì°¸ê³ í•œ í…œí”Œë¦¿ì…ë‹ˆë‹¤. ì‹¤ì œ ì¸í„°í˜ì´ìŠ¤ëŠ” ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” UIX-qwen2 ëª¨ë¸ ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
- ê³µì‹ UIX-qwen2 GitHub ë¬¸ì„œì™€ ëª¨ë¸ ì„¤ëª… í˜ì´ì§€ë¥¼ í•­ìƒ ì°¸ê³ í•˜ì„¸ìš”.  
- í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ì€ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” HuggingFaceì—ì„œ ì§ì ‘ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.  
  (https://huggingface.co/UIX-Engineering/UIX-qwen2 ì™€ ê°™ì€ ëª¨ë¸ í˜ì´ì§€ ì°¸ê³ )  

---
