androidlab에서 seeact와 react 평가 방식의 차이는 무엇인가요

AndroidLab에서 SeeAct와 ReAct는 안드로이드 에이전트의 서로 다른 평가 방식을 나타냅니다. 두 방식의 주요 차이점은 다음과 같습니다:

## SeeAct 평가 방식

SeeAct는 시각적 이해에 기반한 접근법으로:

- **시각적 인식 기반**: 멀티모달 모델(LMM)을 활용하여 스크린샷을 시각적으로 인식한 후 행동을 생성합니다[2]
- **2단계 프로세스**: 
  1. 시각적 인식을 통한 액션 생성(Action Generation): GPT-4V와 같은 LMM을 활용해 웹사이트나 앱을 시각적으로 인식하고 텍스트 형태의 계획을 생성합니다[2]
  2. 액션 그라운딩(Action Grounding): 텍스트 계획을 실제 UI 요소와 연결하여 실행 가능한 작업으로 변환합니다[2]
- **멀티모달 접근**: 이미지(스크린샷)와 텍스트 정보를 모두 활용하는 방식입니다[1][5]

## ReAct 평가 방식

ReAct는 추론 및 행동(Reasoning and Acting) 기반 접근법으로:

- **텍스트 기반 추론**: 주로 XML과 같은 텍스트 기반 표현을 사용하여 UI 구조를 이해하고 추론합니다[1]
- **단계적 추론과 행동**: 모델이 현재 상태를 분석하고 추론한 후 행동을 결정하는 방식으로 작동합니다[1]
- **텍스트 중심**: 멀티모달 정보보다는 텍스트 정보(XML)에 중점을 둔 접근 방식입니다[1]

## AndroidLab의 구현

AndroidLab은 두 가지 기본 작동 모드를 정의하여 이러한 평가 방식을 구현합니다:

- **XML 모드**: UI 요소의 XML 표현을 사용하는 텍스트 기반 모드
- **SoM(Set-of-Mark) 모드**: 스크린샷을 사용하는 시각 기반 모드[1]

각 기본 모드에 대해 ReAct와 SeeAct 두 가지 평가 방식을 적용하여, 텍스트 기반 모델(LLM)과 멀티모달 모델(LMM)이 동일한 액션 스페이스에서 작동할 수 있도록 합니다[1][4].

이러한 다양한 평가 방식을 통해 AndroidLab은 138개의 작업에 걸쳐 안드로이드 에이전트의 성능을 체계적으로 평가할 수 있는 프레임워크를 제공합니다
